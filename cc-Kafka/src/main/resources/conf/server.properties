
# 配置Zookeeper（Hbase时已配置：zoo.cfg文件）
# 配置后分发到其它机器，修改brokerID、kafka服务的主机名，统一配置环境变量

# 设置每个broker全局唯一ID（分发后修改92、93）
broker.id=91

# 设置kafka服务的主机名和端口，监听生产者和消费者提供服务（分发后修改bd92、bd93）
listeners=PLAINTEXT://bd91:9092

# 设置生产者发送到Kafka的消息(数据)，Kafka会将数据保存到'log'文件中(不是程序运行的日志)
# 'log'文件有3类：*.log *.index *.timeindex
log.dirs=/opt/module/kafka-2.4.1/kafka-logs

# 设置数据的生命周期，每条数据写入Kafka时会记录时间戳，超过该周期，Kafka会自动清理（默认168h=7天）
log.retention.hours=168

# 设置'log'数据文件的最大大小，超过该大小滚动生成新文件
log.segment.bytes=1073741824

# 设置允许删除topic（否则只是标记删除）
delete.topic.enable=true

# 设置Kafka连接的zookeeper集群地址
zookeeper.connect=bd91:2181,bd92:2181,bd93:2181


############## 其它配置  ##############

# max.request.size必须小于message.max.bytes及max.partition.fetch.bytes，这样消息才能不断发送

# broker能接收消息的最大字节数(默认1000000)
message.max.bytes=10*1024*1024

# 生产者请求的最大消息体大小(默认1048576)
max.request.size=2.5*1024*1024

# 消费者拉取的最大消息体大小/最大数据量(默认52428800)
#fetch.message.max.bytes=52428800

# 服务器返回的每个分区的最大数据量(默认1048576)
max.partition.fetch.bytes=5*1024*1024


