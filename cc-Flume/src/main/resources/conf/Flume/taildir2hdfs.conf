
######## taildir多个目录或文件监听(不支持递归)to分布式文件管理系统(HDFS) ########
## 支持断点续传：Property：positionFile  Default：~/.flume/taildir_position.json
## JSON格式：记录每个尾文件的inode、最后位置和绝对路径

## agent客户端实例：a1
## 组件：source(数据来源)、sink(数据到哪)、channel(数据传输)

# source组件：r1
a1.sources = r1
# sink组件：k1
a1.sinks = k1
# channel组件：c1
a1.channels = c1

### flume-sources配置：数据来源 ###

# 数据来源类型：taildir多个目录或文件监听(不支持递归)
a1.sources.r1.type = TAILDIR
# 监听的文件组
a1.sources.r1.filegroups = f1 f2
# 组f1监听文件：/opt/b.txt
a1.sources.r1.filegroups.f1 = /opt/b.txt
# 组f2监听目录：/opt/test/.*
# .* 正则匹配；此处不能写*，监控的是文件
a1.sources.r1.filegroups.f2 = /opt/test/.*

### flume-channels配置：数据传输通道缓存类型 ###

# 通道缓存类型：内存
a1.channels.c1.type = memory
# 通道容量
a1.channels.c1.capacity = 1000
# 传输容量/大小(流量)
a1.channels.c1.transactionCapacity = 100

### flume-sinks配置：数据保存 ###

# 数据保存类型：hdfs文件管理系统保存
a1.sinks.k1.type = hdfs
# hdfs输出路径(不能包含:)
a1.sinks.k1.hdfs.path = hdfs://bd91/flume/events/%Y-%m-%d-%H-%M-%S
# 文件前缀
a1.sinks.k1.hdfs.filePrefix = event
# 文件后缀
a1.sinks.k1.hdfs.fileSuffix = .txt
# 文件类型：SequenceFile、DataStream、CompressedStream
a1.sinks.k1.hdfs.fileType = DataStream
# 文件格式：Text、Writable
a1.sinks.k1.hdfs.writeFormat = Text
# 按照时间滚动：每300秒生成一个新文件
a1.sinks.k1.hdfs.hdfs.rollInterval = 300
# 按照文件接收的大小滚动：装满约128M滚动
a1.sinks.k1.hdfs.rollSize = 130000000
# 按照接收的条数滚动：0为不开启
a1.sinks.k1.hdfs.rollCount = 0
# 使用本地时间戳
a1.sinks.k1.hdfs.useLocalTimeStamp = true

## 组件连接绑定

# source连接绑定channel
a1.sources.r1.channels = c1
# channel连接绑定sink
a1.sinks.k1.channel = c1

######## 启动Flume客户端Agent ########
flume-ng agent --conf ../conf/ --conf-file taildir2hdfs.conf --name a1 -Dflume.root.logger=INFO,console
#     命令     |    配置环境     |        配置文件              | agent实例 |          控制台日志打印
#           (../flume-1.9.0/conf/)